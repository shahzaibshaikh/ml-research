{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b495c289-6720-4242-83a2-cdf2526e76d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\University\\Master's Thesis\\Datasets\\rnd\n"
     ]
    }
   ],
   "source": [
    "%cd \"F:\\University\\Master's Thesis\\Datasets\\rnd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e9efc78-d2ca-4bf2-9af7-59595889494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db26b2c6-6c48-434a-b9bd-2753ec74cc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VM</th>\n",
       "      <th>Timestamp [ms]</th>\n",
       "      <th>CPU cores</th>\n",
       "      <th>CPU capacity provisioned [MHZ]</th>\n",
       "      <th>CPU usage [MHZ]</th>\n",
       "      <th>CPU usage [%]</th>\n",
       "      <th>Memory capacity provisioned [KB]</th>\n",
       "      <th>Memory usage [KB]</th>\n",
       "      <th>Disk read throughput [KB/s]</th>\n",
       "      <th>Disk write throughput [KB/s]</th>\n",
       "      <th>Network received throughput [KB/s]</th>\n",
       "      <th>Network transmitted throughput [KB/s]</th>\n",
       "      <th>Memory usage [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VM001</td>\n",
       "      <td>1372629804</td>\n",
       "      <td>2</td>\n",
       "      <td>5851.9989</td>\n",
       "      <td>87.779984</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>8218624.0</td>\n",
       "      <td>1.034593e+06</td>\n",
       "      <td>160.866667</td>\n",
       "      <td>21.733333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>12.588394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VM001</td>\n",
       "      <td>1372630104</td>\n",
       "      <td>2</td>\n",
       "      <td>5851.9989</td>\n",
       "      <td>29.259995</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8218624.0</td>\n",
       "      <td>4.585755e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.579711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VM001</td>\n",
       "      <td>1372630404</td>\n",
       "      <td>2</td>\n",
       "      <td>5851.9989</td>\n",
       "      <td>27.309328</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>8218624.0</td>\n",
       "      <td>1.845480e+05</td>\n",
       "      <td>32.066667</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>2.245485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VM001</td>\n",
       "      <td>1372630704</td>\n",
       "      <td>2</td>\n",
       "      <td>5851.9989</td>\n",
       "      <td>23.407996</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>8218624.0</td>\n",
       "      <td>7.829227e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VM001</td>\n",
       "      <td>1372631004</td>\n",
       "      <td>2</td>\n",
       "      <td>5851.9989</td>\n",
       "      <td>19.506663</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>8218624.0</td>\n",
       "      <td>1.677720e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.041364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      VM  Timestamp [ms]  CPU cores  CPU capacity provisioned [MHZ]  \\\n",
       "0  VM001      1372629804          2                       5851.9989   \n",
       "1  VM001      1372630104          2                       5851.9989   \n",
       "2  VM001      1372630404          2                       5851.9989   \n",
       "3  VM001      1372630704          2                       5851.9989   \n",
       "4  VM001      1372631004          2                       5851.9989   \n",
       "\n",
       "   CPU usage [MHZ]  CPU usage [%]  Memory capacity provisioned [KB]  \\\n",
       "0        87.779984       1.500000                         8218624.0   \n",
       "1        29.259995       0.500000                         8218624.0   \n",
       "2        27.309328       0.466667                         8218624.0   \n",
       "3        23.407996       0.400000                         8218624.0   \n",
       "4        19.506663       0.333333                         8218624.0   \n",
       "\n",
       "   Memory usage [KB]  Disk read throughput [KB/s]  \\\n",
       "0       1.034593e+06                   160.866667   \n",
       "1       4.585755e+05                     0.000000   \n",
       "2       1.845480e+05                    32.066667   \n",
       "3       7.829227e+04                     0.000000   \n",
       "4       1.677720e+05                     0.000000   \n",
       "\n",
       "   Disk write throughput [KB/s]  Network received throughput [KB/s]  \\\n",
       "0                     21.733333                            0.266667   \n",
       "1                      2.333333                            0.200000   \n",
       "2                      4.200000                            0.133333   \n",
       "3                      0.866667                            0.066667   \n",
       "4                      0.200000                            0.133333   \n",
       "\n",
       "   Network transmitted throughput [KB/s]  Memory usage [%]  \n",
       "0                               1.466667         12.588394  \n",
       "1                               1.000000          5.579711  \n",
       "2                               1.066667          2.245485  \n",
       "3                               1.000000          0.952620  \n",
       "4                               1.000000          2.041364  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "\n",
    "# Load Bitbrains dataset into a DataFrame\n",
    "file_path = 'bitbrains_structured_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26329e73-df02-48a0-81dc-1f3b76d31d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "\n",
    "max_prediction_length = 128\n",
    "max_encoder_length = 256\n",
    "training_cutoff = df[\"Timestamp [ms]\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"Timestamp [ms]\",\n",
    "    target=[\"CPU usage [%]\", \"Memory usage [%]\"],\n",
    "    group_ids=[\"VM\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"VM\"],\n",
    "    static_reals=[\"CPU cores\", \"CPU capacity provisioned [MHZ]\", \"Memory capacity provisioned [KB]\"],\n",
    "    time_varying_known_categoricals=[],\n",
    "    time_varying_known_reals=[\"Timestamp [ms]\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        \"CPU usage [%]\",\n",
    "        \"Memory usage [%]\",\n",
    "        \"CPU usage [MHZ]\",\n",
    "        \"Memory usage [KB]\"\n",
    "    ],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"VM\"], transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True,\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
