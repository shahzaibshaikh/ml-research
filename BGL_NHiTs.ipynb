{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf8c6b1-c2c6-451b-8487-4ccc562e64e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\University\\Master's Thesis\\Datasets\n"
     ]
    }
   ],
   "source": [
    "%cd \"F:/University/Master's Thesis/Datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b25943-ce30-4b7f-a521-8fd7ad88c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77a9e7df-5955-4482-be0d-5771e510d6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-forecasting[mqf2] in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (1.0.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: fastapi>=0.80 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from pytorch-forecasting[mqf2]) (0.105.0)\n",
      "Requirement already satisfied: lightning<3.0.0,>=2.0.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from pytorch-forecasting[mqf2]) (2.1.3)\n",
      "Requirement already satisfied: matplotlib in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from pytorch-forecasting[mqf2]) (3.8.0)\n",
      "Requirement already satisfied: optuna<4.0.0,>=3.1.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from pytorch-forecasting[mqf2]) (3.5.0)\n",
      "Requirement already satisfied: pandas<=3.0.0,>=1.3.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from pytorch-forecasting[mqf2]) (1.5.3)\n",
      "Requirement already satisfied: pytorch-optimizer<3.0.0,>=2.5.1 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from pytorch-forecasting[mqf2]) (2.12.0)\n",
      "Requirement already satisfied: scikit-learn<2.0,>=1.2 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from pytorch-forecasting[mqf2]) (1.3.2)\n",
      "Requirement already satisfied: scipy<2.0,>=1.8 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from pytorch-forecasting[mqf2]) (1.11.4)\n",
      "Requirement already satisfied: statsmodels in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from pytorch-forecasting[mqf2]) (0.14.0)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.0.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from pytorch-forecasting[mqf2]) (2.1.2)\n",
      "Collecting cpflows<0.2.0,>=0.1.2 (from pytorch-forecasting[mqf2])\n",
      "  Downloading cpflows-0.1.2.tar.gz (42 kB)\n",
      "     ---------------------------------------- 0.0/42.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.9/42.9 kB 2.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting backports.functools-lru-cache>=1.6.1 (from cpflows<0.2.0,>=0.1.2->pytorch-forecasting[mqf2])\n",
      "  Downloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: cycler>=0.10.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from cpflows<0.2.0,>=0.1.2->pytorch-forecasting[mqf2]) (0.11.0)\n",
      "Collecting future>=0.17.1 (from cpflows<0.2.0,>=0.1.2->pytorch-forecasting[mqf2])\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "     ---------------------------------------- 0.0/840.9 kB ? eta -:--:--\n",
      "     ------------------------------------  839.7/840.9 kB 26.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- 840.9/840.9 kB 17.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from cpflows<0.2.0,>=0.1.2->pytorch-forecasting[mqf2]) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.16 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from cpflows<0.2.0,>=0.1.2->pytorch-forecasting[mqf2]) (1.26.2)\n",
      "Requirement already satisfied: pyparsing>=2.4.7 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from cpflows<0.2.0,>=0.1.2->pytorch-forecasting[mqf2]) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from cpflows<0.2.0,>=0.1.2->pytorch-forecasting[mqf2]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from cpflows<0.2.0,>=0.1.2->pytorch-forecasting[mqf2]) (2023.3.post1)\n",
      "Requirement already satisfied: seaborn>=0.9.1 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from cpflows<0.2.0,>=0.1.2->pytorch-forecasting[mqf2]) (0.12.2)\n",
      "Requirement already satisfied: six>=1.15.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from cpflows<0.2.0,>=0.1.2->pytorch-forecasting[mqf2]) (1.16.0)\n",
      "Collecting subprocess32>=3.5.3 (from cpflows<0.2.0,>=0.1.2->pytorch-forecasting[mqf2])\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "     ---------------------------------------- 0.0/97.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 97.4/97.4 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torchvision (from cpflows<0.2.0,>=0.1.2->pytorch-forecasting[mqf2])\n",
      "  Downloading torchvision-0.16.2-cp310-cp310-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tqdm>=4.23 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from cpflows<0.2.0,>=0.1.2->pytorch-forecasting[mqf2]) (4.65.0)\n",
      "Requirement already satisfied: h5py in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from cpflows<0.2.0,>=0.1.2->pytorch-forecasting[mqf2]) (3.9.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from fastapi>=0.80->pytorch-forecasting[mqf2]) (3.7.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from fastapi>=0.80->pytorch-forecasting[mqf2]) (2.5.2)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from fastapi>=0.80->pytorch-forecasting[mqf2]) (0.27.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from fastapi>=0.80->pytorch-forecasting[mqf2]) (4.9.0)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (6.0.1)\n",
      "Requirement already satisfied: fsspec<2025.0,>=2022.5.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (2023.10.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (0.10.0)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (23.1)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (1.2.1)\n",
      "Requirement already satisfied: pytorch-lightning in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from matplotlib->pytorch-forecasting[mqf2]) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from matplotlib->pytorch-forecasting[mqf2]) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from matplotlib->pytorch-forecasting[mqf2]) (10.0.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from optuna<4.0.0,>=3.1.0->pytorch-forecasting[mqf2]) (1.13.1)\n",
      "Requirement already satisfied: colorlog in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from optuna<4.0.0,>=3.1.0->pytorch-forecasting[mqf2]) (6.8.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from optuna<4.0.0,>=3.1.0->pytorch-forecasting[mqf2]) (2.0.21)\n",
      "Requirement already satisfied: joblib>=1.1.1 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting[mqf2]) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting[mqf2]) (2.2.0)\n",
      "Requirement already satisfied: filelock in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (3.13.1)\n",
      "Requirement already satisfied: sympy in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (1.12)\n",
      "Requirement already satisfied: networkx in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (3.1)\n",
      "Requirement already satisfied: jinja2 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (3.1.2)\n",
      "Requirement already satisfied: patsy>=0.5.2 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from statsmodels->pytorch-forecasting[mqf2]) (0.5.3)\n",
      "Requirement already satisfied: Mako in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from alembic>=1.5.0->optuna<4.0.0,>=3.1.0->pytorch-forecasting[mqf2]) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.80->pytorch-forecasting[mqf2]) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.80->pytorch-forecasting[mqf2]) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.80->pytorch-forecasting[mqf2]) (1.0.4)\n",
      "Requirement already satisfied: requests in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (3.9.0)\n",
      "Requirement already satisfied: setuptools in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from lightning-utilities<2.0,>=0.8.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (68.2.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.80->pytorch-forecasting[mqf2]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.80->pytorch-forecasting[mqf2]) (2.14.5)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna<4.0.0,>=3.1.0->pytorch-forecasting[mqf2]) (3.0.1)\n",
      "Requirement already satisfied: colorama in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from tqdm>=4.23->cpflows<0.2.0,>=0.1.2->pytorch-forecasting[mqf2]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from jinja2->torch<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from sympy->torch<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\software\\anaconda\\envs\\deeplearning-env\\lib\\site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting[mqf2]) (2023.11.17)\n",
      "Downloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl (6.7 kB)\n",
      "Downloading torchvision-0.16.2-cp310-cp310-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 24.0 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: cpflows, future, subprocess32\n",
      "  Building wheel for cpflows (setup.py): started\n",
      "  Building wheel for cpflows (setup.py): finished with status 'done'\n",
      "  Created wheel for cpflows: filename=cpflows-0.1.2-py3-none-any.whl size=54304 sha256=4276b9aee19a2f0f3bce5fc8a1305e0d51ca4748ba1cc36bb6d5eada6909f886\n",
      "  Stored in directory: c:\\users\\shahzaib shaikh\\appdata\\local\\pip\\cache\\wheels\\1b\\c3\\fd\\cdcca84615eb336ec3d17d9d1fd858684240e91b47cf3dab6e\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492054 sha256=bd064f69ef3e731909d868df3be1c401295fdcde1aa5452cee5e78c83481a0a7\n",
      "  Stored in directory: c:\\users\\shahzaib shaikh\\appdata\\local\\pip\\cache\\wheels\\5e\\a9\\47\\f118e66afd12240e4662752cc22cefae5d97275623aa8ef57d\n",
      "  Building wheel for subprocess32 (setup.py): started\n",
      "  Building wheel for subprocess32 (setup.py): finished with status 'done'\n",
      "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6499 sha256=c7d933eef1d9b3a54dea5529a6319713807680d74a6f9340b9128d64fb37344d\n",
      "  Stored in directory: c:\\users\\shahzaib shaikh\\appdata\\local\\pip\\cache\\wheels\\64\\19\\61\\d440ccd46a2a014bce61fc5c6c8495dedd32ef04cba8b34b28\n",
      "Successfully built cpflows future subprocess32\n",
      "Installing collected packages: subprocess32, future, backports.functools-lru-cache, torchvision, cpflows\n",
      "Successfully installed backports.functools-lru-cache-2.0.0 cpflows-0.1.2 future-0.18.3 subprocess32-3.5.4 torchvision-0.16.2\n"
     ]
    }
   ],
   "source": [
    "%pip install pytorch-forecasting[mqf2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f81122-ff3d-43e8-a8ab-66f7122cd7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, NHiTS, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "from pytorch_forecasting.data.examples import generate_ar_data\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, MQF2DistributionLoss, QuantileLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94dd2afa-f8ee-4b2b-83be-ddcf80d0e9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineId</th>\n",
       "      <th>Label</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>Node</th>\n",
       "      <th>Time</th>\n",
       "      <th>NodeRepeat</th>\n",
       "      <th>Type</th>\n",
       "      <th>Component</th>\n",
       "      <th>Level</th>\n",
       "      <th>Content</th>\n",
       "      <th>EventId</th>\n",
       "      <th>EventTemplate</th>\n",
       "      <th>ParameterList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1186991</td>\n",
       "      <td>-</td>\n",
       "      <td>1119695655</td>\n",
       "      <td>2005.06.25</td>\n",
       "      <td>R32-M0-NA-C:J14-U11</td>\n",
       "      <td>2005-06-25-03.34.15.417108</td>\n",
       "      <td>R32-M0-NA-C:J14-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>254619084 double-hummer alignment exceptions</td>\n",
       "      <td>6265c739</td>\n",
       "      <td>&lt;*&gt; double-hummer alignment exceptions</td>\n",
       "      <td>['254619084']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1186992</td>\n",
       "      <td>-</td>\n",
       "      <td>1119695655</td>\n",
       "      <td>2005.06.25</td>\n",
       "      <td>R32-M0-NA-C:J10-U11</td>\n",
       "      <td>2005-06-25-03.34.15.438456</td>\n",
       "      <td>R32-M0-NA-C:J10-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>255442463 double-hummer alignment exceptions</td>\n",
       "      <td>6265c739</td>\n",
       "      <td>&lt;*&gt; double-hummer alignment exceptions</td>\n",
       "      <td>['255442463']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1186993</td>\n",
       "      <td>-</td>\n",
       "      <td>1119695655</td>\n",
       "      <td>2005.06.25</td>\n",
       "      <td>R32-M0-NA-C:J10-U11</td>\n",
       "      <td>2005-06-25-03.34.15.451519</td>\n",
       "      <td>R32-M0-NA-C:J10-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>256867576 double-hummer alignment exceptions</td>\n",
       "      <td>6265c739</td>\n",
       "      <td>&lt;*&gt; double-hummer alignment exceptions</td>\n",
       "      <td>['256867576']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1186994</td>\n",
       "      <td>-</td>\n",
       "      <td>1119695655</td>\n",
       "      <td>2005.06.25</td>\n",
       "      <td>R32-M0-NA-C:J06-U11</td>\n",
       "      <td>2005-06-25-03.34.15.472919</td>\n",
       "      <td>R32-M0-NA-C:J06-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>255099253 double-hummer alignment exceptions</td>\n",
       "      <td>6265c739</td>\n",
       "      <td>&lt;*&gt; double-hummer alignment exceptions</td>\n",
       "      <td>['255099253']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1186995</td>\n",
       "      <td>-</td>\n",
       "      <td>1119695655</td>\n",
       "      <td>2005.06.25</td>\n",
       "      <td>R32-M0-NA-C:J06-U11</td>\n",
       "      <td>2005-06-25-03.34.15.486042</td>\n",
       "      <td>R32-M0-NA-C:J06-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>258522516 double-hummer alignment exceptions</td>\n",
       "      <td>6265c739</td>\n",
       "      <td>&lt;*&gt; double-hummer alignment exceptions</td>\n",
       "      <td>['258522516']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LineId Label   Timestamp        Date                 Node  \\\n",
       "0  1186991     -  1119695655  2005.06.25  R32-M0-NA-C:J14-U11   \n",
       "1  1186992     -  1119695655  2005.06.25  R32-M0-NA-C:J10-U11   \n",
       "2  1186993     -  1119695655  2005.06.25  R32-M0-NA-C:J10-U11   \n",
       "3  1186994     -  1119695655  2005.06.25  R32-M0-NA-C:J06-U11   \n",
       "4  1186995     -  1119695655  2005.06.25  R32-M0-NA-C:J06-U11   \n",
       "\n",
       "                         Time           NodeRepeat Type Component Level  \\\n",
       "0  2005-06-25-03.34.15.417108  R32-M0-NA-C:J14-U11  RAS    KERNEL  INFO   \n",
       "1  2005-06-25-03.34.15.438456  R32-M0-NA-C:J10-U11  RAS    KERNEL  INFO   \n",
       "2  2005-06-25-03.34.15.451519  R32-M0-NA-C:J10-U11  RAS    KERNEL  INFO   \n",
       "3  2005-06-25-03.34.15.472919  R32-M0-NA-C:J06-U11  RAS    KERNEL  INFO   \n",
       "4  2005-06-25-03.34.15.486042  R32-M0-NA-C:J06-U11  RAS    KERNEL  INFO   \n",
       "\n",
       "                                        Content   EventId  \\\n",
       "0  254619084 double-hummer alignment exceptions  6265c739   \n",
       "1  255442463 double-hummer alignment exceptions  6265c739   \n",
       "2  256867576 double-hummer alignment exceptions  6265c739   \n",
       "3  255099253 double-hummer alignment exceptions  6265c739   \n",
       "4  258522516 double-hummer alignment exceptions  6265c739   \n",
       "\n",
       "                            EventTemplate  ParameterList  \n",
       "0  <*> double-hummer alignment exceptions  ['254619084']  \n",
       "1  <*> double-hummer alignment exceptions  ['255442463']  \n",
       "2  <*> double-hummer alignment exceptions  ['256867576']  \n",
       "3  <*> double-hummer alignment exceptions  ['255099253']  \n",
       "4  <*> double-hummer alignment exceptions  ['258522516']  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BGL dataset into a DataFrame (Replace 'path_to_your_file' with the actual file path)\n",
    "file_path = 'bgl_structured_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9e1a3de-80ff-4a34-8010-2d84ba0d2887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Node Level  time_idx Component  \\\n",
      "1644188  R02-M1-N0-C:J12-U11  INFO        15    KERNEL   \n",
      "1644253  R02-M1-N0-C:J12-U11  INFO        38    KERNEL   \n",
      "1644260  R02-M1-N0-C:J12-U11  INFO        40    KERNEL   \n",
      "1644269  R02-M1-N0-C:J12-U11  INFO        44    KERNEL   \n",
      "1644292  R02-M1-N0-C:J12-U11  INFO        52    KERNEL   \n",
      "...                      ...   ...       ...       ...   \n",
      "2356265  R37-M1-N0-C:J02-U11  INFO  15353606    KERNEL   \n",
      "2356266  R51-M1-N0-C:J08-U11  INFO  15353606    KERNEL   \n",
      "2356267  R37-M0-N0-C:J05-U11  INFO  15353606    KERNEL   \n",
      "2356259  R10-M1-NC-C:J05-U01  INFO  15353606    KERNEL   \n",
      "2356251  R57-M1-N7-C:J11-U11  INFO  15353606    KERNEL   \n",
      "\n",
      "                                             EventTemplate  \n",
      "1644188           instruction cache parity error corrected  \n",
      "1644253           instruction cache parity error corrected  \n",
      "1644260           instruction cache parity error corrected  \n",
      "1644269           instruction cache parity error corrected  \n",
      "1644292           instruction cache parity error corrected  \n",
      "...                                                    ...  \n",
      "2356265  <*> microseconds spent in the rbs signal handl...  \n",
      "2356266  <*> total interrupts. <*> critical input inter...  \n",
      "2356267  <*> total interrupts. <*> critical input inter...  \n",
      "2356259  <*> total interrupts. <*> critical input inter...  \n",
      "2356251  <*> microseconds spent in the rbs signal handl...  \n",
      "\n",
      "[2559277 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df[\"Time\"] = pd.to_datetime(df[\"Time\"], format='%Y-%m-%d-%H.%M.%S.%f')\n",
    "\n",
    "# Calculate time_idx for seconds\n",
    "df[\"time_idx\"] = (\n",
    "    df[\"Time\"].dt.year * 365 * 24 * 60 * 60 +  # Convert years to seconds\n",
    "    df[\"Time\"].dt.month * 30 * 24 * 60 * 60 +  # Convert months to seconds (assuming 30 days per month)\n",
    "    df[\"Time\"].dt.day * 24 * 60 * 60 +  # Convert days to seconds\n",
    "    df[\"Time\"].dt.hour * 60 * 60 +  # Convert hours to seconds\n",
    "    df[\"Time\"].dt.minute * 60 +  # Convert minutes to seconds\n",
    "    df[\"Time\"].dt.second  # Seconds\n",
    ")\n",
    "\n",
    "# Adjust time_idx to start from 0\n",
    "df[\"time_idx\"] -= df[\"time_idx\"].min()\n",
    "df = df.sort_values(by=\"time_idx\")\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "df = df.drop_duplicates(subset=['time_idx', 'Node', \"EventId\"], keep=False)\n",
    "\n",
    "# Display the DataFrame with the new time_idx column\n",
    "print(df[[\"Node\", \"Level\", \"time_idx\", \"Component\", \"EventTemplate\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb7cb5ab-df52-4666-9db5-60a474ef47c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516\n"
     ]
    }
   ],
   "source": [
    "unique_values = df['EventId'].unique()\n",
    "print(len(unique_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6de23bf-a274-412a-9cf4-2337ab842a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Node'].fillna('-', inplace=True)\n",
    "\n",
    "df['Node'] = df['Node'].astype('str')\n",
    "df['Component'] = df['Component'].astype('str')\n",
    "df['Level'] = df['Level'].astype('str')\n",
    "df['EventId'] = df['EventId'].astype('str')\n",
    "df['EventTemplate'] = df['EventTemplate'].astype('str')\n",
    "\n",
    "df['Node'] = df['Node'].astype('category')\n",
    "df['Component'] = df['Component'].astype('category')\n",
    "df['Level'] = df['Level'].astype('category')\n",
    "df['EventId'] = df['EventId'].astype('category')\n",
    "df['EventTemplate'] = df['EventTemplate'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "867fd28a-fa66-4c24-89d7-20468a8b6034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_idx: int64\n",
      "Node: category\n",
      "Component: category\n",
      "Level: category\n",
      "EventId: category\n",
      "EventTemplate: category\n"
     ]
    }
   ],
   "source": [
    "data_type = df['time_idx'].dtype\n",
    "print(\"time_idx: \" + str(data_type))\n",
    "\n",
    "data_type = df['Node'].dtype\n",
    "print(\"Node: \" + str(data_type))\n",
    "\n",
    "data_type = df['Component'].dtype\n",
    "print(\"Component: \" + str(data_type))\n",
    "\n",
    "data_type = df['Level'].dtype\n",
    "print(\"Level: \" + str(data_type))\n",
    "\n",
    "data_type = df['EventId'].dtype\n",
    "print(\"EventId: \" + str(data_type))\n",
    "\n",
    "data_type = df['EventTemplate'].dtype\n",
    "print(\"EventTemplate: \" + str(data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c961b9c6-dabb-40a5-a505-5c84c03f3f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty rows in 'Node': 0\n"
     ]
    }
   ],
   "source": [
    "# Replace 'Column_Name' with the name of the column you're interested in\n",
    "empty_rows = df['Node'].isnull().sum()\n",
    "\n",
    "print(f\"Number of empty rows in 'Node': {empty_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b3fd571-8d03-4ff1-8a80-9c50f5695447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineId</th>\n",
       "      <th>Label</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>Node</th>\n",
       "      <th>Time</th>\n",
       "      <th>NodeRepeat</th>\n",
       "      <th>Type</th>\n",
       "      <th>Component</th>\n",
       "      <th>Level</th>\n",
       "      <th>Content</th>\n",
       "      <th>EventId</th>\n",
       "      <th>EventTemplate</th>\n",
       "      <th>ParameterList</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1644188</th>\n",
       "      <td>237496</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838585</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:43:05.980712</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>3aa50e45</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>[]</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644253</th>\n",
       "      <td>237561</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838608</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:43:28.948656</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>3aa50e45</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>[]</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644260</th>\n",
       "      <td>237568</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838610</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:43:30.008754</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>3aa50e45</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>[]</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644269</th>\n",
       "      <td>237577</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838614</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:43:34.978903</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>3aa50e45</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>[]</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644292</th>\n",
       "      <td>237600</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838622</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:43:42.042890</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>3aa50e45</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>[]</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LineId Label   Timestamp        Date                 Node  \\\n",
       "1644188  237496     -  1117838585  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "1644253  237561     -  1117838608  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "1644260  237568     -  1117838610  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "1644269  237577     -  1117838614  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "1644292  237600     -  1117838622  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "\n",
       "                              Time           NodeRepeat Type Component Level  \\\n",
       "1644188 2005-06-03 15:43:05.980712  R02-M1-N0-C:J12-U11  RAS    KERNEL  INFO   \n",
       "1644253 2005-06-03 15:43:28.948656  R02-M1-N0-C:J12-U11  RAS    KERNEL  INFO   \n",
       "1644260 2005-06-03 15:43:30.008754  R02-M1-N0-C:J12-U11  RAS    KERNEL  INFO   \n",
       "1644269 2005-06-03 15:43:34.978903  R02-M1-N0-C:J12-U11  RAS    KERNEL  INFO   \n",
       "1644292 2005-06-03 15:43:42.042890  R02-M1-N0-C:J12-U11  RAS    KERNEL  INFO   \n",
       "\n",
       "                                          Content   EventId  \\\n",
       "1644188  instruction cache parity error corrected  3aa50e45   \n",
       "1644253  instruction cache parity error corrected  3aa50e45   \n",
       "1644260  instruction cache parity error corrected  3aa50e45   \n",
       "1644269  instruction cache parity error corrected  3aa50e45   \n",
       "1644292  instruction cache parity error corrected  3aa50e45   \n",
       "\n",
       "                                    EventTemplate ParameterList  time_idx  \n",
       "1644188  instruction cache parity error corrected            []        15  \n",
       "1644253  instruction cache parity error corrected            []        38  \n",
       "1644260  instruction cache parity error corrected            []        40  \n",
       "1644269  instruction cache parity error corrected            []        44  \n",
       "1644292  instruction cache parity error corrected            []        52  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65d4617f-3810-49ef-a4c9-e6b955afa161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNKNOWN_LOCATION       4607\n",
      "R30-M0-N7-C:J09-U01    3912\n",
      "R63-M0-N3-C:J02-U11    3816\n",
      "R35-M0-N0-C:J07-U01    2972\n",
      "R37-M1-NC-C:J02-U11    1824\n",
      "R06-M1-N6-C:J15-U01    1812\n",
      "R20-M1-NF-C:J10-U01    1618\n",
      "R16-M1-N2-C:J17-U01    1555\n",
      "R10-M0-N7-C:J17-U01    1518\n",
      "R00-M1-NF-C:J13-U11    1246\n",
      "R55-M0-N9-C:J06-U11    1217\n",
      "R10-M1-N5-C:J04-U11     950\n",
      "R07-M0-N6-C:J11-U01     898\n",
      "R63-M1-NC-C:J06-U01     897\n",
      "-                       801\n",
      "R21-M0-ND-C:J04-U01     767\n",
      "R15-M1-N6-C:J04-U11     731\n",
      "R03-M1-NF-C:J07-U01     697\n",
      "R23-M0-N8-C:J15-U11     689\n",
      "R01-M0-N8-C:J02-U11     686\n",
      "R22-M1-N3-C:J06-U01     671\n",
      "R73-M1-N1-C:J16-U11     670\n",
      "R32-M0-NF-C:J14-U01     658\n",
      "R61-M1-ND-C:J07-U11     656\n",
      "R03-M1-N9-C:J09-U11     654\n",
      "R11-M1-N3-C:J07-U11     647\n",
      "R32-M1-N9-C:J16-U11     647\n",
      "R25-M1-ND-C:J09-U01     646\n",
      "R16-M1-N2-C:J16-U11     645\n",
      "R17-M0-N0-C:J10-U01     635\n",
      "Name: Node, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "top_lengths = df['Node'].value_counts().head(30)\n",
    "print(top_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b073d684-8843-4a3e-93e0-9d2f07428177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodes_to_remove = ['R30-M0-N9-C:J16-U01', 'R02-M1-N0-C:J12-U11', \"-\", \"UNKNOWN_LOCATION\", \"R16-M1-N2-C:J17-U01\", \"R26-M0-N0-I:J18-U11\", \"R02-M0-N4-C:J04-U11\"]  # Example list of nodes to remove\n",
    "nodes_to_remove = [\"UNKNOWN_LOCATION\", \"-\"]  # Example list of nodes to remove\n",
    "\n",
    "# Removing rows where 'Node' column matches specified nodes\n",
    "df = df[~df['Node'].isin(nodes_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6882d47-3df9-432a-ad6f-d58e2947f7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 2553869\n"
     ]
    }
   ],
   "source": [
    "total_rows = len(df)  # Retrieves the length of the DataFrame (number of rows)\n",
    "print(\"Total number of rows:\", total_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "732fdc83-bb36-44fc-9691-ed66c7a6029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and dataloaders\n",
    "max_encoder_length = 60\n",
    "max_prediction_length = 20\n",
    "\n",
    "training_cutoff = df[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "context_length = max_encoder_length\n",
    "prediction_length = max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    df[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"EventId\",\n",
    "    categorical_encoders={\"Node\": NaNLabelEncoder().fit(df.Node), \"EventId\": NaNLabelEncoder().fit(df.EventId),\"Component\": NaNLabelEncoder().fit(df.Component), \"Level\": NaNLabelEncoder().fit(df.Level)},\n",
    "    group_ids=[\"Node\"],\n",
    "    # only unknown variable is \"value\" - and N-HiTS can also not take any additional variables\n",
    "    time_varying_unknown_reals=[],\n",
    "    time_varying_unknown_categoricals=[\"Component\", \"Level\", \"EventId\"],  # Adjust this based on features\n",
    "    max_encoder_length=context_length,\n",
    "    max_prediction_length=prediction_length,\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(training, df, predict=True, stop_randomization=True)\n",
    "batch_size = 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f50f19de-e123-49a4-a164-02ca62f023cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Software\\Anaconda\\envs\\deeplearning-env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0118)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate baseline absolute error\n",
    "baseline_predictions = Baseline().predict(val_dataloader, trainer_kwargs=dict(accelerator=\"cpu\"), return_y=True)\n",
    "SMAPE()(baseline_predictions.output, baseline_predictions.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85f889e7-0acb-4fc4-a59e-018a6abc6411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "only regression tasks are supported - target must not be categorical",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m early_stop_callback \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[0;32m      3\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m      4\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     enable_checkpointing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     10\u001b[0m )\n\u001b[1;32m---> 13\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mNHiTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_val_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackcast_loss_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAdamW\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mQuantileLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     26\u001b[0m     net,\n\u001b[0;32m     27\u001b[0m     train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[0;32m     28\u001b[0m     val_dataloaders\u001b[38;5;241m=\u001b[39mval_dataloader,\n\u001b[0;32m     29\u001b[0m )\n",
      "File \u001b[1;32mF:\\Software\\Anaconda\\envs\\deeplearning-env\\lib\\site-packages\\pytorch_forecasting\\models\\nhits\\__init__.py:321\u001b[0m, in \u001b[0;36mNHiTS.from_dataset\u001b[1;34m(cls, dataset, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03mConvenience function to create network from :py:class`~pytorch_forecasting.data.timeseries.TimeSeriesDataSet`.\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    NBeats\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# validate arguments\u001b[39;00m\n\u001b[1;32m--> 321\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    322\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mtarget_normalizer, NaNLabelEncoder\n\u001b[0;32m    323\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly regression tasks are supported - target must not be categorical\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    325\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mmin_encoder_length \u001b[38;5;241m==\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmax_encoder_length\n\u001b[0;32m    326\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly fixed encoder length is allowed, but min_encoder_length != max_encoder_length\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    329\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mmax_prediction_length \u001b[38;5;241m==\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmin_prediction_length\n\u001b[0;32m    330\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly fixed prediction length is allowed, but max_prediction_length != min_prediction_length\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: only regression tasks are supported - target must not be categorical"
     ]
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"cpu\",\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=1.0,\n",
    "    callbacks=[early_stop_callback],\n",
    "    limit_train_batches=30,\n",
    "    enable_checkpointing=True,\n",
    ")\n",
    "\n",
    "\n",
    "net = NHiTS.from_dataset(\n",
    "    training,\n",
    "    learning_rate=5e-3,\n",
    "    log_interval=10,\n",
    "    log_val_interval=1,\n",
    "    weight_decay=1e-2,\n",
    "    backcast_loss_ratio=0.0,\n",
    "    hidden_size=64,\n",
    "    optimizer=\"AdamW\",\n",
    "    loss=MQF2DistributionLoss(prediction_length=max_prediction_length),\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    net,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49c607f-2525-4f5e-8876-f64108f4307a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
